{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration - COVIDSenti Dataset\n",
    "\n",
    "Comprehensive analysis of the dataset to understand:\n",
    "- Total tweet counts\n",
    "- News vs conversational distribution\n",
    "- Sentiment distribution\n",
    "- Example tweets by category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the parsed dataset (with syntactic parses)\n",
    "df = pd.read_csv(\"../data/input_data/COVIDSenti/COVIDSenti_full_parsed.csv\")\n",
    "\n",
    "print(f\"Total tweets: {len(df):,}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label distribution\n",
    "print(\"Sentiment Distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "print(f\"\\nPercentages:\")\n",
    "print(df['label'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Tweet length\n",
    "df['tweet_length'] = df['tweet'].str.len()\n",
    "df['word_count'] = df['tweet'].str.split().str.len()\n",
    "\n",
    "print(f\"\\nTweet Statistics:\")\n",
    "print(f\"  Average length: {df['tweet_length'].mean():.0f} characters\")\n",
    "print(f\"  Average words: {df['word_count'].mean():.1f}\")\n",
    "print(f\"  Min words: {df['word_count'].min()}\")\n",
    "print(f\"  Max words: {df['word_count'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart\n",
    "df['label'].value_counts().plot(kind='bar', ax=ax1, color=['#95a5a6', '#e74c3c', '#2ecc71'])\n",
    "ax1.set_title('Sentiment Distribution (All Tweets)', fontsize=14)\n",
    "ax1.set_xlabel('Sentiment')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_xticklabels(['Neutral', 'Negative', 'Positive'], rotation=0)\n",
    "\n",
    "# Pie chart\n",
    "df['label'].value_counts().plot(kind='pie', ax=ax2, autopct='%1.1f%%', \n",
    "                                colors=['#95a5a6', '#e74c3c', '#2ecc71'])\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_title('All 90,000 Tweets', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News vs Conversational Filter\n",
    "\n",
    "**Improved Multi-Signal Filter:**\n",
    "\n",
    "**Strong news patterns (immediate filter):**\n",
    "- Title | Format: \"Coronavirus | CDC Updates\"\n",
    "- \"via @username\" (shared news)\n",
    "- \"RT @\" (retweets)\n",
    "- **NEW:** \"Organization on Topic:\" (e.g., \"Wyoming Public Health on Coronavirus:\")\n",
    "- **NEW:** Colon + quote marks (quoted statements)\n",
    "\n",
    "**Conversational signals (hierarchical):**\n",
    "1. **First-person pronouns** (STRONG): \"I\", \"my\", \"me\", \"we\", \"our\"\n",
    "   - Always conversational, even with URL\n",
    "   - Example: \"I have to admit #Covid19 sounds better... https://...\"\n",
    "\n",
    "2. **Question marks**: Usually conversational (people asking questions)\n",
    "\n",
    "3. **Opinion + punctuation**: Opinion words + (? or !) \n",
    "\n",
    "4. **Second-person + opinion**: \"you/your\" + opinion words\n",
    "   - Distinguishes \"your hands\" (directive) from \"your opinion\" (conversational)\n",
    "\n",
    "5. **URLs without signals**: Likely news if no strong personal language\n",
    "\n",
    "**Key improvement:** More nuanced than simple pattern matching - considers multiple signals and their combinations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_news_like(tweet):\n",
    "    tweet_lower = tweet.lower()\n",
    "\n",
    "    strong_news_patterns = [\n",
    "        r\"^[A-Z][a-z]+ \\| \",\n",
    "        r\"\\bvia @\",\n",
    "        r\"^RT @\",\n",
    "        r\"^[A-Z][a-z\\s]+ on [A-Z][a-z]+:\",\n",
    "        r':\\s*[\"\\u201c\\u2018]',\n",
    "    ]\n",
    "\n",
    "    news_hashtags = [\n",
    "        r\"#smartnews\",\n",
    "        r\"#breakingnews\",\n",
    "        r\"#breaking\",\n",
    "        r\"#news\",\n",
    "        r\"#topstory\",\n",
    "        r\"#headline\",\n",
    "        r\"#update\",\n",
    "        r\"#alert\",\n",
    "        r\"#cnn\",\n",
    "        r\"#fox\",\n",
    "        r\"#bbc\",\n",
    "        r\"#msnbc\",\n",
    "        r\"#reuters\",\n",
    "    ]\n",
    "\n",
    "    for pattern in strong_news_patterns:\n",
    "        if re.search(pattern, tweet):\n",
    "            return True\n",
    "\n",
    "    for hashtag in news_hashtags:\n",
    "        if hashtag in tweet_lower:\n",
    "            return True\n",
    "\n",
    "    first_person = [\n",
    "        \"i \",\n",
    "        \"my \",\n",
    "        \"me \",\n",
    "        \"i'm\",\n",
    "        \"i've\",\n",
    "        \"i'd\",\n",
    "        \"i'll\",\n",
    "        \"we \",\n",
    "        \"our \",\n",
    "        \"we're\",\n",
    "        \"we've\",\n",
    "        \"we'll\",\n",
    "    ]\n",
    "    has_first_person = any(word in tweet_lower for word in first_person)\n",
    "\n",
    "    has_question = \"?\" in tweet\n",
    "\n",
    "    if has_first_person or has_question:\n",
    "        return False\n",
    "\n",
    "    if len(tweet.split()) < 5:\n",
    "        return True\n",
    "\n",
    "    headline_patterns = [\n",
    "        r\"^[A-Z][a-z\\s]+ (man|woman|person|official|doctor|patient|resident)\",\n",
    "        r\"\\b(reports?|says?|confirms?|announces?|warns?|urges?)\\s+(that|about)\",\n",
    "        r\"^\\w+\\s+(is|was|has been|have been)\\s+the\\s+(first|second|latest)\",\n",
    "    ]\n",
    "\n",
    "    for pattern in headline_patterns:\n",
    "        if re.search(pattern, tweet):\n",
    "            return True\n",
    "\n",
    "    second_person = [\"you \", \"your \", \"you're\", \"you've\", \"you'll\"]\n",
    "    has_second_person = any(word in tweet_lower for word in second_person)\n",
    "\n",
    "    has_exclamation = \"!\" in tweet\n",
    "\n",
    "    opinion_words = [\n",
    "        \"think\",\n",
    "        \"feel\",\n",
    "        \"believe\",\n",
    "        \"hope\",\n",
    "        \"wish\",\n",
    "        \"hate\",\n",
    "        \"love\",\n",
    "        \"like\",\n",
    "        \"dislike\",\n",
    "        \"want\",\n",
    "        \"need\",\n",
    "        \"afraid\",\n",
    "        \"worried\",\n",
    "        \"glad\",\n",
    "        \"happy\",\n",
    "        \"sad\",\n",
    "        \"angry\",\n",
    "        \"confused\",\n",
    "        \"admit\",\n",
    "        \"crap\",\n",
    "        \"damn\",\n",
    "        \"wow\",\n",
    "        \"omg\",\n",
    "        \"wtf\",\n",
    "        \"lol\",\n",
    "        \"lmao\",\n",
    "    ]\n",
    "    has_opinion = any(word in tweet_lower for word in opinion_words)\n",
    "\n",
    "    has_url = bool(re.search(r\"https?://\", tweet))\n",
    "\n",
    "    if has_opinion and has_exclamation:\n",
    "        return False\n",
    "\n",
    "    if has_second_person and has_opinion:\n",
    "        return False\n",
    "\n",
    "    if has_url:\n",
    "        return True\n",
    "\n",
    "    institutional = bool(\n",
    "        re.search(\n",
    "            r\"\\b(CDC|WHO|NIH|FDA|Health Department|Public Health)\\b\",\n",
    "            tweet,\n",
    "            re.IGNORECASE,\n",
    "        )\n",
    "    )\n",
    "    if institutional:\n",
    "        return True\n",
    "\n",
    "    return True\n",
    "    \n",
    "\n",
    "df['is_news'] = df['tweet'].apply(is_news_like)\n",
    "\n",
    "news_count = df['is_news'].sum()\n",
    "conversational_count = (~df['is_news']).sum()\n",
    "\n",
    "print(f\"  News-like tweets: {news_count:,} ({news_count/len(df)*100:.1f}%)\")\n",
    "print(f\"  Conversational tweets: {conversational_count:,} ({conversational_count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['is_news']==True][\"label\"].value_counts() / len(df[df['is_news']==True]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['is_news']==True) &  (df['label']==\"neg\")] [\"tweet\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Distribution: News vs Conversational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = df[df['is_news']]\n",
    "df_conv = df[~df['is_news']]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# News tweets\n",
    "df_news['label'].value_counts().plot(kind='bar', ax=ax1, color=['#95a5a6', '#e74c3c', '#2ecc71'])\n",
    "ax1.set_title(f'News-like Tweets (n={len(df_news):,})', fontsize=12)\n",
    "ax1.set_xlabel('Sentiment')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_xticklabels(['Neutral', 'Negative', 'Positive'], rotation=0)\n",
    "\n",
    "# Conversational tweets\n",
    "label_counts = df_conv['label'].value_counts()\n",
    "label_names = {'neu': 'Neutral', 'neg': 'Negative', 'pos': 'Positive'}\n",
    "label_colors = {'neu': '#95a5a6', 'neg': '#e74c3c', 'pos': '#2ecc71'}\n",
    "display_labels = [label_names.get(lbl, lbl) for lbl in label_counts.index]\n",
    "colors = [label_colors.get(lbl, '#3498db') for lbl in label_counts.index]\n",
    "\n",
    "label_counts.plot(kind='bar', ax=ax2, color=colors)\n",
    "ax2.set_title(f'Conversational Tweets (n={len(df_conv):,})', fontsize=12)\n",
    "ax2.set_xlabel('Sentiment')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_xticklabels(display_labels, rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNews-like sentiment:\")\n",
    "print(df_news['label'].value_counts())\n",
    "print(\"\\nConversational sentiment:\")\n",
    "print(df_conv['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Tweets - News-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"NEWS-LIKE TWEETS (filtered out for ABSA)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Show random news tweets\n",
    "news_sample = df_news.sample(n=10, random_state=42)\n",
    "for i, (idx, row) in enumerate(news_sample.iterrows(), 1):\n",
    "    print(f\"\\n{i}. [{row['label'].upper()}] {row['tweet']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Tweets - Conversational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"CONVERSATIONAL TWEETS (kept for ABSA)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Show random conversational tweets\n",
    "conv_sample = df_conv.sample(n=min(20, len(df_conv)), random_state=42)\n",
    "for i, (idx, row) in enumerate(conv_sample.iterrows(), 1):\n",
    "    print(f\"\\n{i}. [{row['label'].upper()}] {row['tweet']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational Tweets by Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show conversational examples grouped by sentiment\n",
    "for sentiment in ['neg', 'neu', 'pos']:\n",
    "    sentiment_tweets = df_conv[df_conv['label'] == sentiment]\n",
    "    if len(sentiment_tweets) == 0:\n",
    "        continue\n",
    "    \n",
    "    sentiment_name = {'neg': 'NEGATIVE', 'neu': 'NEUTRAL', 'pos': 'POSITIVE'}[sentiment]\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"{sentiment_name} Conversational Tweets (n={len(sentiment_tweets):,})\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Show up to 10 examples\n",
    "    sample = sentiment_tweets.sample(n=min(10, len(sentiment_tweets)), random_state=42)\n",
    "    for i, (idx, row) in enumerate(sample.iterrows(), 1):\n",
    "        print(f\"\\n{i}. {row['tweet']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare tweet lengths\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Word count - News\n",
    "axes[0,0].hist(df_news['word_count'], bins=50, edgecolor='black', alpha=0.7, color='#e74c3c')\n",
    "axes[0,0].axvline(df_news['word_count'].mean(), color='blue', linestyle='--', label='Mean')\n",
    "axes[0,0].set_title('News-like Tweets - Word Count')\n",
    "axes[0,0].set_xlabel('Words')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Word count - Conversational\n",
    "axes[0,1].hist(df_conv['word_count'], bins=50, edgecolor='black', alpha=0.7, color='#2ecc71')\n",
    "axes[0,1].axvline(df_conv['word_count'].mean(), color='blue', linestyle='--', label='Mean')\n",
    "axes[0,1].set_title('Conversational Tweets - Word Count')\n",
    "axes[0,1].set_xlabel('Words')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Character length - News\n",
    "axes[1,0].hist(df_news['tweet_length'], bins=50, edgecolor='black', alpha=0.7, color='#e74c3c')\n",
    "axes[1,0].axvline(df_news['tweet_length'].mean(), color='blue', linestyle='--', label='Mean')\n",
    "axes[1,0].set_title('News-like Tweets - Character Length')\n",
    "axes[1,0].set_xlabel('Characters')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# Character length - Conversational\n",
    "axes[1,1].hist(df_conv['tweet_length'], bins=50, edgecolor='black', alpha=0.7, color='#2ecc71')\n",
    "axes[1,1].axvline(df_conv['tweet_length'].mean(), color='blue', linestyle='--', label='Mean')\n",
    "axes[1,1].set_title('Conversational Tweets - Character Length')\n",
    "axes[1,1].set_xlabel('Characters')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Average word count:\")\n",
    "print(f\"  News-like: {df_news['word_count'].mean():.1f}\")\n",
    "print(f\"  Conversational: {df_conv['word_count'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Conversational Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"data/COVIDSenti/COVIDSenti_conversational_only.csv\"\n",
    "df_conv.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(df_conv):,} conversational tweets to:\")\n",
    "print(f\"  {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
