{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Download\n",
    "\n",
    "Download datasets for COVID-19 ABSA and emotion analysis.\n",
    "\n",
    "**Authors:** Marko Haralović, Onat Akca, Salih Eren Yücetürk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COVIDSenti Dataset\n",
    "\n",
    "90,000 COVID-19 tweets with sentiment labels (positive, negative, neutral).\n",
    "\n",
    "**Source:** https://github.com/usmaann/COVIDSenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/s3758869/synchain-absa-emotion\n",
      "Data directory: /home/s3758869/synchain-absa-emotion/data/input_data/COVIDSenti\n",
      "Downloading to: /home/s3758869/synchain-absa-emotion/data/input_data/COVIDSenti\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "data_dir = project_root / 'data' / 'input_data' / 'COVIDSenti' / 'raw'\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Downloading to: {data_dir.absolute()}\\n\")\n",
    "\n",
    "datasets = {\n",
    "   'COVIDSenti-A': 'https://raw.githubusercontent.com/usmaann/COVIDSenti/main/COVIDSenti-A.csv',\n",
    "   'COVIDSenti-B': 'https://raw.githubusercontent.com/usmaann/COVIDSenti/main/COVIDSenti-B.csv',\n",
    "   'COVIDSenti-C': 'https://raw.githubusercontent.com/usmaann/COVIDSenti/main/COVIDSenti-C.csv',\n",
    "   'COVIDSenti-Full': 'https://raw.githubusercontent.com/usmaann/COVIDSenti/main/COVIDSenti.csv'\n",
    "}\n",
    "\n",
    "for name, url in datasets.items():\n",
    "   response = requests.get(url)\n",
    "   if response.status_code == 200:\n",
    "      filepath = data_dir / f'{name}.csv'\n",
    "      filepath.write_bytes(response.content)\n",
    "\n",
    "   else:\n",
    "      print(f\"Failed to download {name}: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METS-CoV Dataset\n",
    "\n",
    "Medical Entity and Targeted Sentiment on COVID-19 tweets.\n",
    "\n",
    "**Source:** https://github.com/YLab-Open/METS-CoV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/home/s3758869/synchain-absa-emotion/data/METS-CoV-temp'...\n",
      "remote: Enumerating objects: 69, done.\u001b[K\n",
      "remote: Enumerating objects: 69, done.\u001b[K\n",
      "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
      "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
      "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
      "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
      "remote: Total 69 (delta 39), reused 50 (delta 27), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (69/69), 7.05 MiB | 34.55 MiB/s, done.\n",
      "remote: Total 69 (delta 39), reused 50 (delta 27), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (69/69), 7.05 MiB | 34.55 MiB/s, done.\n",
      "Resolving deltas: 100% (39/39), done.\n",
      "Resolving deltas: 100% (39/39), done.\n",
      "total 1.5K\n",
      "-rw-r--r-- 1 s3758869 30019 306K Dec 12 15:48 MEST-CoV-test.csv\n",
      "-rw-r--r-- 1 s3758869 30019 307K Dec 12 15:48 METS-CoV-dev.csv\n",
      "-rw-r--r-- 1 s3758869 30019 1.5M Dec 12 15:48 METS-CoV-train.csv\n",
      "total 1.5K\n",
      "-rw-r--r-- 1 s3758869 30019 306K Dec 12 15:48 MEST-CoV-test.csv\n",
      "-rw-r--r-- 1 s3758869 30019 307K Dec 12 15:48 METS-CoV-dev.csv\n",
      "-rw-r--r-- 1 s3758869 30019 1.5M Dec 12 15:48 METS-CoV-train.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "mets_temp = project_root / 'data' / 'METS-CoV-temp'\n",
    "mets_dir = project_root / 'data' / 'input_data' / 'METS-CoV' / 'raw'\n",
    "\n",
    "!git clone https://github.com/YLab-Open/METS-CoV.git {mets_temp}\n",
    "\n",
    "mets_dir.mkdir(parents=True, exist_ok=True)\n",
    "import shutil\n",
    "for file in (mets_temp / 'dataset').glob('*'):\n",
    "    shutil.move(str(file), str(mets_dir / file.name))\n",
    "\n",
    "shutil.rmtree(mets_temp)\n",
    "\n",
    "!ls -lh {mets_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SenWave Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/s3758869/synchain-absa-emotion\n",
      "Data directory: /home/s3758869/synchain-absa-emotion/data/input_data/SenWave\n",
      "Downloading to: /home/s3758869/synchain-absa-emotion/data/input_data/SenWave\n",
      "\n",
      "Downloaded SenWave\n",
      "Downloaded SenWave\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "data_dir = project_root / 'data' / 'input_data' / 'SenWave' / 'raw'\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Downloading to: {data_dir.absolute()}\\n\")\n",
    "\n",
    "datasets = {\n",
    "   'SenWave': 'https://raw.githubusercontent.com/gitdevqiang/SenWave/main/labeledtweets/labeledEn.csv',\n",
    "}\n",
    "\n",
    "for name, url in datasets.items():\n",
    "   response = requests.get(url)\n",
    "   if response.status_code == 200:\n",
    "      filepath = data_dir / f'{name}.csv'\n",
    "      filepath.write_bytes(response.content)\n",
    "      print(f\"Downloaded {name}\")\n",
    "   else:\n",
    "      print(f\"Failed to download {name}: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COVID-19 NLP Text Classification (Kaggle)\n",
    "\n",
    "-  https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification\n",
    "\n",
    "- download `kaggle.json` from https://www.kaggle.com/settings/account and place it in `~/.kaggle/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification\n",
      "License(s): copyright-authors\n",
      "Downloading covid-19-nlp-text-classification.zip to /home/s3758869/synchain-absa-emotion/data/input_data/COVID-19-NLP\n",
      "Downloading covid-19-nlp-text-classification.zip to /home/s3758869/synchain-absa-emotion/data/input_data/COVID-19-NLP\n",
      "  0%|                                               | 0.00/4.38M [00:00<?, ?B/s]\n",
      "100%|███████████████████████████████████████| 4.38M/4.38M [00:00<00:00, 199MB/s]\n",
      "  0%|                                               | 0.00/4.38M [00:00<?, ?B/s]\n",
      "100%|███████████████████████████████████████| 4.38M/4.38M [00:00<00:00, 199MB/s]\n",
      "\n",
      "Dataset downloaded to: /home/s3758869/synchain-absa-emotion/data/input_data/COVID-19-NLP\n",
      "\n",
      "Dataset downloaded to: /home/s3758869/synchain-absa-emotion/data/input_data/COVID-19-NLP\n",
      "total 1.0K\n",
      "-rw-r--r-- 1 s3758869 30019 979K Dec 12 16:34 Corona_NLP_test.csv\n",
      "-rw-r--r-- 1 s3758869 30019  11M Dec 12 16:34 Corona_NLP_train.csv\n",
      "total 1.0K\n",
      "-rw-r--r-- 1 s3758869 30019 979K Dec 12 16:34 Corona_NLP_test.csv\n",
      "-rw-r--r-- 1 s3758869 30019  11M Dec 12 16:34 Corona_NLP_train.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "kaggle_dir = project_root / 'data' / 'input_data' / 'COVID-19-NLP' / 'raw'\n",
    "kaggle_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "!kaggle datasets download -d datatattle/covid-19-nlp-text-classification -p {kaggle_dir} --unzip\n",
    "\n",
    "print(f\"\\nDataset downloaded to: {kaggle_dir}\")\n",
    "!ls -lh {kaggle_dir}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aria_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
